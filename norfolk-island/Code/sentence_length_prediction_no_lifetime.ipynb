{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fde49eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01f07343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected dimension: 117\n",
      "X_train shape: (1628, 116)\n",
      "X_val shape: (543, 116)\n",
      "X_test shape: (543, 116)\n",
      "y_train shape: (1628,)\n",
      "y_val shape: (543,)\n",
      "y_test shape: (543,)\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing\n",
    "\n",
    "# Enable and disable features\n",
    "\n",
    "data = pd.read_csv('VDL_Norfolk_Island_Penal_Colony_Cleaned_No_Outliers.csv')\n",
    "data = data.drop(columns=['trial_id'])\n",
    "\n",
    "TARGET_VARIABLE = 'pp_sentence_years'\n",
    "\n",
    "# A mapping to boolean indicating that whether a feature is enabled, do not use enabled_features\n",
    "ENABLED_FEATURE_MAPPING = {\n",
    "    'offence_pp_general': True,\n",
    "    'offence_pp': True,\n",
    "    'pp_sentence_years': True,\n",
    "    'trial_month': True,\n",
    "    'trial_year': True,\n",
    "    'trial_place': True,\n",
    "    'pris_ht_pp': True,\n",
    "    'def_age_pp': True,\n",
    "    'def_literacy': True,\n",
    "    'def_religion_pp': True,\n",
    "    'marital_status_pp': True,\n",
    "    'children_nr': False,\n",
    "    'cash_sav_pp': False,\n",
    "    'occupation_pp': True,\n",
    "    'coloffence_info': True,\n",
    "    'offence_ni': True,\n",
    "    'death_in_custody_pp': True,\n",
    "    'length_of_stay_until_probat': False,\n",
    "    'length_of_stay_until_tl': False,\n",
    "    'previous_convictions': True\n",
    "}\n",
    "# 4 disabled features\n",
    "\n",
    "\n",
    "# ENABLED_FEATURE_MAPPING = {\n",
    "#     'offence_pp_general': True,\n",
    "#     'offence_pp': False,\n",
    "#     'pp_sentence_years': True,\n",
    "#     'trial_month': False,\n",
    "#     'trial_year': False,\n",
    "#     'trial_place': False,\n",
    "#     'pris_ht_pp': False,\n",
    "#     'def_age_pp': True,\n",
    "#     'def_literacy': True,\n",
    "#     'def_religion_pp': True,\n",
    "#     'marital_status_pp': True,\n",
    "#     'children_nr': False,\n",
    "#     'cash_sav_pp': False,\n",
    "#     'occupation_pp': False,\n",
    "#     'coloffence_info': True,\n",
    "#     'offence_ni': True,\n",
    "#     'death_in_custody_pp': True,\n",
    "#     'length_of_stay_until_probat': False,\n",
    "#     'length_of_stay_until_tl': False,\n",
    "#     'previous_convictions': True\n",
    "# }\n",
    "# # offence_pp_general, def_age_pp, def_literacy, def_religion_pp, marital_status_pp, coloffence_info, offence_ni, death_in_custody_pp, previous_convictions\n",
    "\n",
    "\n",
    "ENABLED_FEATURE_MAPPING = {\n",
    "    'offence_pp_general': True,\n",
    "    'offence_pp': True,\n",
    "    'pp_sentence_years': True,\n",
    "    'trial_month': True,\n",
    "    'trial_year': True,\n",
    "    'trial_place': True,\n",
    "    'pris_ht_pp': True,\n",
    "    'def_age_pp': True,\n",
    "    'def_literacy': True,\n",
    "    'def_religion_pp': True,\n",
    "    'marital_status_pp': True,\n",
    "    'children_nr': True,\n",
    "    'cash_sav_pp': True,\n",
    "    'occupation_pp': True,\n",
    "    'coloffence_info': True,\n",
    "    'offence_ni': True,\n",
    "    'death_in_custody_pp': True,\n",
    "    'length_of_stay_until_probat': True,\n",
    "    'length_of_stay_until_tl': True,\n",
    "    'previous_convictions': True\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# A mapping to boolean indicating that whether a feature is numerical\n",
    "FEATURE_TYPE_MAPPING = {\n",
    "    'offence_pp_general': False,\n",
    "    'offence_pp': False,\n",
    "    'pp_sentence_years': True,\n",
    "    'trial_month': True,\n",
    "    'trial_year': True,\n",
    "    'trial_place': False,\n",
    "    'pris_ht_pp': True,\n",
    "    'def_age_pp': True,\n",
    "    'def_literacy': True,\n",
    "    'def_religion_pp': False,\n",
    "    'marital_status_pp': False,\n",
    "    'children_nr': True,\n",
    "    'cash_sav_pp': True,\n",
    "    'occupation_pp': False,\n",
    "    'coloffence_info': True,\n",
    "    'offence_ni': True,\n",
    "    'death_in_custody_pp': True,\n",
    "    'length_of_stay_until_probat': True,\n",
    "    'length_of_stay_until_tl': True,\n",
    "    'previous_convictions': True\n",
    "}\n",
    "\n",
    "# Remove all row with pp_sentence_years = 99\n",
    "data = data[data['pp_sentence_years'] != 99]\n",
    "\n",
    "# Select only the enabled features\n",
    "data = data[[col for col in data.columns if ENABLED_FEATURE_MAPPING[col] or col == TARGET_VARIABLE]]\n",
    "\n",
    "# Move the target variable to the end of the dataframe\n",
    "data = data[[col for col in data.columns if col != TARGET_VARIABLE] + [TARGET_VARIABLE]]\n",
    "\n",
    "# Move all numerical features to the left of the categorical features\n",
    "numerical_features = [col for col in data.columns if FEATURE_TYPE_MAPPING[col] and col != TARGET_VARIABLE]\n",
    "categorical_features = [col for col in data.columns if not FEATURE_TYPE_MAPPING[col] and col != TARGET_VARIABLE]\n",
    "data = data[numerical_features + categorical_features + [TARGET_VARIABLE]]\n",
    "\n",
    "# Normalize the numerical features\n",
    "def normalize_data(data):\n",
    "    for col in data.columns:\n",
    "        if FEATURE_TYPE_MAPPING[col] and col != TARGET_VARIABLE:\n",
    "            data[col] = (data[col] - data[col].mean()) / data[col].std()\n",
    "    return data\n",
    "data = normalize_data(data)\n",
    "\n",
    "# Expect total dimension num_numerical_features + num_categorical_features * number of unique values + 1\n",
    "dim_expected = len(numerical_features) + sum([len(data[col].unique()) for col in categorical_features]) + 1\n",
    "print(f\"Expected dimension: {dim_expected}\")\n",
    "\n",
    "# Backup data before one-hot encoding\n",
    "data_backup = data.copy()\n",
    "\n",
    "# # For each categorical feature, convert it to a one-hot encoding\n",
    "def one_hot_encode(data):\n",
    "    for col in data.columns:\n",
    "        if not FEATURE_TYPE_MAPPING[col] and col != TARGET_VARIABLE:\n",
    "            one_hot = pd.get_dummies(data[col], prefix=col)\n",
    "            data = data.drop(col, axis=1)\n",
    "            data = pd.concat([data, one_hot], axis=1)\n",
    "    return data\n",
    "data = one_hot_encode(data)\n",
    "\n",
    "assert data.shape[1] == dim_expected, f\"Data shape {data.shape[1]} does not match expected dimension {dim_expected}\"\n",
    "\n",
    "# Move the target variable to the end of the dataframe again\n",
    "data = data[[col for col in data.columns if col != TARGET_VARIABLE] + [TARGET_VARIABLE]]\n",
    "\n",
    "# Convert everything to float\n",
    "data = data.astype(float)\n",
    "\n",
    "# Convert to numpy array\n",
    "data = data.to_numpy()\n",
    "\n",
    "# Split the data into training, validation, and test sets 60/20/20\n",
    "X = data[:, :-1]\n",
    "y = data[:, -1]\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_val shape: {y_val.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f316b4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 66.37826769\n",
      "Iteration 2, loss = 58.28986521\n",
      "Iteration 3, loss = 48.63420428\n",
      "Iteration 4, loss = 36.91423675\n",
      "Iteration 5, loss = 24.04491781\n",
      "Iteration 6, loss = 13.31665634\n",
      "Iteration 7, loss = 8.64139994\n",
      "Iteration 8, loss = 7.95198407\n",
      "Iteration 9, loss = 7.21575198\n",
      "Iteration 10, loss = 6.60852450\n",
      "Iteration 11, loss = 6.36727938\n",
      "Iteration 12, loss = 6.19722112\n",
      "Iteration 13, loss = 6.06570305\n",
      "Iteration 14, loss = 5.94776400\n",
      "Iteration 15, loss = 5.84540115\n",
      "Iteration 16, loss = 5.76381220\n",
      "Iteration 17, loss = 5.69468892\n",
      "Iteration 18, loss = 5.62690239\n",
      "Iteration 19, loss = 5.55866643\n",
      "Iteration 20, loss = 5.49545131\n",
      "Iteration 21, loss = 5.44092935\n",
      "Iteration 22, loss = 5.39361806\n",
      "Iteration 23, loss = 5.35499959\n",
      "Iteration 24, loss = 5.30765205\n",
      "Iteration 25, loss = 5.26897943\n",
      "Iteration 26, loss = 5.22804995\n",
      "Iteration 27, loss = 5.19435971\n",
      "Iteration 28, loss = 5.16564892\n",
      "Iteration 29, loss = 5.13244506\n",
      "Iteration 30, loss = 5.09801001\n",
      "Iteration 31, loss = 5.07155033\n",
      "Iteration 32, loss = 5.03875617\n",
      "Iteration 33, loss = 5.00177667\n",
      "Iteration 34, loss = 4.96742765\n",
      "Iteration 35, loss = 4.94606950\n",
      "Iteration 36, loss = 4.91126191\n",
      "Iteration 37, loss = 4.88496567\n",
      "Iteration 38, loss = 4.87100661\n",
      "Iteration 39, loss = 4.83737422\n",
      "Iteration 40, loss = 4.80321041\n",
      "Iteration 41, loss = 4.78270296\n",
      "Iteration 42, loss = 4.76158593\n",
      "Iteration 43, loss = 4.72698012\n",
      "Iteration 44, loss = 4.71153077\n",
      "Iteration 45, loss = 4.68134326\n",
      "Iteration 46, loss = 4.64866689\n",
      "Iteration 47, loss = 4.65363872\n",
      "Iteration 48, loss = 4.64819305\n",
      "Iteration 49, loss = 4.59377649\n",
      "Iteration 50, loss = 4.57305245\n",
      "Architecture: (75, 50), MSE: 10.646290874885588, MAE: 2.6393319020040127, max_iter: 50, actual_iter: 50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dm/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (50) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "architectures = [\n",
    "    (75,50), # 1 hidden layer × 50 neurons\n",
    "    # (100,), # 1 hidden layer × 100 neurons\n",
    "    # (100, 50) # 2 hidden layers × 100 and 50 neurons\n",
    "]\n",
    "\n",
    "scoring = 'neg_mean_squared_error'\n",
    "\n",
    "# Initialize the MLPRegressor\n",
    "score_list_mse = []\n",
    "score_list_mae = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "max_iter = 50\n",
    "\n",
    "for architecture in architectures:\n",
    "    model = MLPRegressor(\n",
    "        hidden_layer_sizes=architecture,\n",
    "        activation='relu',\n",
    "        solver='adam',\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        verbose=True,\n",
    "    )\n",
    "    # Compute the MSE score on the validation set\n",
    "    model.fit(X_train, y_train)\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    mse = np.mean((y_val - y_val_pred) ** 2)\n",
    "    mae = np.mean(np.abs(y_val - y_val_pred))\n",
    "\n",
    "    print(f\"Architecture: {architecture}, MSE: {mse}, MAE: {mae}, max_iter: {max_iter}, actual_iter: {model.n_iter_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb0a645a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 66.37826769\n",
      "Iteration 2, loss = 58.28986521\n",
      "Iteration 3, loss = 48.63420428\n",
      "Iteration 4, loss = 36.91423675\n",
      "Iteration 5, loss = 24.04491781\n",
      "Iteration 6, loss = 13.31665634\n",
      "Iteration 7, loss = 8.64139994\n",
      "Iteration 8, loss = 7.95198407\n",
      "Iteration 9, loss = 7.21575198\n",
      "Iteration 10, loss = 6.60852450\n",
      "Iteration 11, loss = 6.36727938\n",
      "Iteration 12, loss = 6.19722112\n",
      "Iteration 13, loss = 6.06570305\n",
      "Iteration 14, loss = 5.94776400\n",
      "Iteration 15, loss = 5.84540115\n",
      "Iteration 16, loss = 5.76381220\n",
      "Iteration 17, loss = 5.69468892\n",
      "Iteration 18, loss = 5.62690239\n",
      "Iteration 19, loss = 5.55866643\n",
      "Iteration 20, loss = 5.49545131\n",
      "Iteration 21, loss = 5.44092935\n",
      "Iteration 22, loss = 5.39361806\n",
      "Iteration 23, loss = 5.35499959\n",
      "Iteration 24, loss = 5.30765205\n",
      "Iteration 25, loss = 5.26897943\n",
      "Iteration 26, loss = 5.22804995\n",
      "Iteration 27, loss = 5.19435971\n",
      "Iteration 28, loss = 5.16564892\n",
      "Iteration 29, loss = 5.13244506\n",
      "Iteration 30, loss = 5.09801001\n",
      "Iteration 31, loss = 5.07155033\n",
      "Iteration 32, loss = 5.03875617\n",
      "Iteration 33, loss = 5.00177667\n",
      "Iteration 34, loss = 4.96742765\n",
      "Iteration 35, loss = 4.94606950\n",
      "Iteration 36, loss = 4.91126191\n",
      "Iteration 37, loss = 4.88496567\n",
      "Iteration 38, loss = 4.87100661\n",
      "Iteration 39, loss = 4.83737422\n",
      "Iteration 40, loss = 4.80321041\n",
      "Iteration 41, loss = 4.78270296\n",
      "Iteration 42, loss = 4.76158593\n",
      "Iteration 43, loss = 4.72698012\n",
      "Iteration 44, loss = 4.71153077\n",
      "Iteration 45, loss = 4.68134326\n",
      "Iteration 46, loss = 4.64866689\n",
      "Iteration 47, loss = 4.65363872\n",
      "Iteration 48, loss = 4.64819305\n",
      "Iteration 49, loss = 4.59377649\n",
      "Iteration 50, loss = 4.57305245\n",
      "Iteration 51, loss = 4.53557635\n",
      "Iteration 52, loss = 4.52402859\n",
      "Iteration 53, loss = 4.49205590\n",
      "Iteration 54, loss = 4.48328795\n",
      "Iteration 55, loss = 4.44962204\n",
      "Iteration 56, loss = 4.41947627\n",
      "Iteration 57, loss = 4.39127275\n",
      "Iteration 58, loss = 4.36975096\n",
      "Iteration 59, loss = 4.34524304\n",
      "Iteration 60, loss = 4.31200711\n",
      "Iteration 61, loss = 4.28871277\n",
      "Iteration 62, loss = 4.26472535\n",
      "Iteration 63, loss = 4.23142634\n",
      "Iteration 64, loss = 4.21075026\n",
      "Iteration 65, loss = 4.18503238\n",
      "Iteration 66, loss = 4.15146449\n",
      "Iteration 67, loss = 4.13873339\n",
      "Iteration 68, loss = 4.10206766\n",
      "Iteration 69, loss = 4.09263556\n",
      "Iteration 70, loss = 4.05292544\n",
      "Iteration 71, loss = 4.01731521\n",
      "Iteration 72, loss = 3.98945882\n",
      "Iteration 73, loss = 3.95700114\n",
      "Iteration 74, loss = 3.90768842\n",
      "Iteration 75, loss = 3.88539373\n",
      "Iteration 76, loss = 3.85042969\n",
      "Iteration 77, loss = 3.82714523\n",
      "Iteration 78, loss = 3.80687739\n",
      "Iteration 79, loss = 3.77037446\n",
      "Iteration 80, loss = 3.74650473\n",
      "Iteration 81, loss = 3.70960771\n",
      "Iteration 82, loss = 3.68053883\n",
      "Iteration 83, loss = 3.66103753\n",
      "Iteration 84, loss = 3.64345584\n",
      "Iteration 85, loss = 3.59715838\n",
      "Iteration 86, loss = 3.59929891\n",
      "Iteration 87, loss = 3.55340231\n",
      "Iteration 88, loss = 3.52480228\n",
      "Iteration 89, loss = 3.47592419\n",
      "Iteration 90, loss = 3.45264352\n",
      "Iteration 91, loss = 3.42973883\n",
      "Iteration 92, loss = 3.40960614\n",
      "Iteration 93, loss = 3.38200772\n",
      "Iteration 94, loss = 3.34647759\n",
      "Iteration 95, loss = 3.32431768\n",
      "Iteration 96, loss = 3.29662179\n",
      "Iteration 97, loss = 3.26999669\n",
      "Iteration 98, loss = 3.23896649\n",
      "Iteration 99, loss = 3.21560109\n",
      "Iteration 100, loss = 3.19475804\n",
      "Final evaluation on test set, Architecture: (75, 50), MSE: 11.826674711145602, MAE: 2.7466945541026093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/dm/lib/python3.13/site-packages/sklearn/neural_network/_multilayer_perceptron.py:691: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation on test set\n",
    "best_architecture = architectures[0]\n",
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=best_architecture,\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    max_iter=100,\n",
    "    random_state=42,\n",
    "    verbose=True,\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "mse = np.mean((y_test - y_test_pred) ** 2)\n",
    "mae = np.mean(np.abs(y_test - y_test_pred))\n",
    "print(f\"Final evaluation on test set, Architecture: {best_architecture}, MSE: {mse}, MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b2e3aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
